import torch

UNK = 0  # Index for unknown tokens
PAD = 1  # Index for padding tokens
BATCH_SIZE = 128  # Size of each training batch
TRAIN_FILE = './data/trainp.txt'  # Training dataset file path
DEV_FILE = './data/devp.txt'  # Development/Validation dataset file path
TEST_FILE = './data/testp.txt'  # Test dataset file path
SAVE_FILE = 'save/n_modelpDataAug.pt'  # Path to save the trained model (ensure the 'save' folder exists)
LAYERS = 6  # Number of layers in both encoder and decoder
D_MODEL = 512  # Embedding dimension size
D_FF = 1024  # Dimension of the first feed-forward layer
H_NUM = 8  # Number of heads in multi-head attention
DROPOUT = 0.1  # Dropout rate
EPOCHS = 100  # Number of training epochs
MAX_LENGTH = 60  # Maximum sequence length
SRC_VOCAB = 11488 # Vocabulary size for the source language (e.g., English)
TGT_VOCAB = 22200  # Vocabulary size for the target language (e.g., Telugu)

# Paths for BLEU score evaluation (specific to DEV file)
BLEU_REFERENCES = "bleu/afterAUG/reference.txt"  # Reference translations for BLEU evaluation
BLEU_CANDIDATE = "bleu/afterAUG/candidate.txt"  # Candidate translations generated by the model
# BLEU_REFERENCES = "bleu/cleaned_reference.txt"  # Reference translations for BLEU evaluation
# BLEU_CANDIDATE = "bleu/cleaned_candidate.txt"  # Candidate translations generated by the model
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Use GPU if available, otherwise use CPU


# BLEU_REFERENCES = "bleu/afterAUG/reference.txt" 
# BLEU_CANDIDATE = "bleu/afterAUG/candidate.txt"  

